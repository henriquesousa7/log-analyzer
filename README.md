# Log Analyzer
> Last Version: __1.0.0__

## An√°lise de Logs Web com Apache Spark

Este projeto tem como objetivo processar e analisar logs de acesso a um servidor web utilizando **Apache Spark**, a fim de extrair informa√ß√µes relevantes sobre o comportamento dos usu√°rios e o desempenho da infraestrutura.  

A solu√ß√£o √© empacotada via **Docker** e **Docker Compose**, com os resultados persistidos em **Parquet** para  serem visualizados via **Streamlit**.

---

## Desafio Proposto

A an√°lise dos logs responde √†s seguintes quest√µes:

1. **Top 10 IPs:** Quais s√£o os 10 IPs de origem com maior n√∫mero de acessos?
2. **Top 6 Endpoints:** Quais s√£o os 6 endpoints mais acessados, desconsiderando arquivos est√°ticos como `.js`, `.css`, `.png`, etc.?
3. **IPs Distintos:** Quantos IPs √∫nicos acessaram o servidor?
4. **Dias √önicos:** Quantos dias diferentes est√£o representados nos logs?
5. **Estat√≠sticas de Tamanho das Respostas:**
   - Volume total de dados retornados.
   - Maior volume de dados em uma √∫nica resposta.
   - Menor volume de dados em uma √∫nica resposta.
   - Volume m√©dio de dados retornado.
6. **Dia com Mais Erros 4xx:** Qual dia da semana teve mais respostas com erros do tipo "HTTP Client Error" (c√≥digos 4xx)?

Os resultados s√£o persistidos em **Parquet**, utilizando a Arquitetura de medalh√£o.

---

## Requisitos e Instala√ß√£o

### Pr√©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas:

- **Docker Desktop** (Windows/macOS): [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
- **Docker Engine** e **Docker Compose** (Linux):  
  - [Instalar Docker Engine](https://docs.docker.com/engine/install/)  
  - [Instalar Docker Compose](https://docs.docker.com/compose/install/)

### Clonando o Reposit√≥rio

```bash
git clone https://github.com/henriquesousa7/web-log-analysis.git
cd web-log-analysis
```

---

## Como Executar o Projeto

### 1. Construir as Imagens Docker

No diret√≥rio raiz (onde est√° o `docker-compose.yml`), execute:

```bash
docker-compose build --no-cache
```

> O uso do `--no-cache` √© recomendado na primeira execu√ß√£o ou ap√≥s altera√ß√µes em depend√™ncias ou no Dockerfile.

### 2. Iniciar os Servi√ßos

Execute os containers com:

```bash
docker-compose up
```

> Os servi√ßos incluem:
> - **log-analyzer**: processa os logs e gera os arquivos do tipo Parquet de sa√≠da.

Para rodar em segundo plano:

```bash
docker-compose up -d
```

### 3. Verificar os Resultados

- **Parquets Gerados:** Localizados em `./data_outputs` (mapeado de `/app/data_outputs` no container).
- **Logs:** Ser√£o exibidos no terminal ou podem ser acessados via `docker logs`.

### 4. Encerrar os Servi√ßos

```bash
docker-compose down
```

Para remover tamb√©m os volumes persistentes (incluindo banco e sa√≠da de dados):

```bash
docker-compose down -v
```

---

## Visualiza√ß√£o de Dados com Streamlit

Ap√≥s os steps de processamento e ingest√£o, uma aplica√ß√£o **Streamlit** √© iniciada para gerar dashboards interativos baseados no arquivo **JSON** exportado.  

A interface facilita a explora√ß√£o dos dados de forma visual e acess√≠vel.

üîó Acesse a aplica√ß√£o:  
```
http://localhost:8501/
```

---

## Justificativa da Persist√™ncia

Optou-se pelo uso do formato **Parquet** por ser colunar, compacto e altamente eficiente para an√°lises com o Apache Spark. Essa escolha facilita futuras consultas e integra√ß√µes com ferramentas anal√≠ticas, otimizando a leitura e o armazenamento dos dados processados a partir dos logs (Volume alto de dados, sendo baseado por n users e n timestamps).

---